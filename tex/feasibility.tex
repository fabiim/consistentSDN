%!TEX root = ../PEI.tex
\label{sec:feasibility:apps}
\glsresetall



\subsubsection{what you want to show in this chapter} 


\begin{itemize}
\item Key take-away: ?

\item  We implemented a prototype of the described distributed controller
architecture integrating applications from the Floodlight
controller~\footnote{\url{http://www.projectfloodlight.org/floodlight/}} with a
data store built using a state-of-the-art state machine replication
library, BFT-SMaRt~\cite{smart-tr,bft-smart:2011:High-perfomance}.

\item  In this section we explain how this applications work, the
  modifications done in the integration process and an analysis of the
  data store performance 

\item It is also worth noting that we have made
an effort to avoid behavioral changes to the applications.
To the best of our knowledge the exposed services of
the applications we changed are virtually indistinguishable
from their predecessors.
\end{itemize}

\subsubsection{Workloads}

\begin{itemize}
\item The objective of the experiment is to analyze the workloads generated by these applications to thereafter measure the performance of the data store when subject to such realistic demand.
\item What are they? 
\item Workloads are fundamental to helps us understand what kind of
  changes in the controller-to-data store interaction that have most
  impact in performance. 
\item We will reveal our iterative process in optimizing the
  applications.  % tradeoffs if we have the code changes. 
\item In fact, the data store functionalites developed (described in
  section \ref{sec:heimdall:datastore} only exist as a consequence of
  the observed behaviour of those applications. Fundamental to help
  understand and improve in the applications. Hopefully useful for
  some reader. 

 \item Focused on data plane plane events in isolation . Considered in isolation,
 other applications behaviour can impact on the workloads  by
 communicating with the application API.
\item We do not log creation,
 deletion of tables, since in our experiences those are not relevant  these happen very
 infrequently (only on the first message or so). 
\item  We classify OF
packet-in requests according to the network packet they
encapsulate.
\item Introduzir imagem 
\end{itemize}



\subsubsection{Feasibility study explanation}


The feasibility study was done in two phases.

\begin{itemize}

\item First, we emulated a network environment in Mininet  --- a network
emulation platform that enables a virtual network, running real
kernel,switch and application code, on a single machine
\cite{Handigol:2012t} ---  that consisted of a single switch and at
least a pair of host devices.

\item ICMP requests (pings) were then generated between pairs of host
  devices.

\item The objective was to create OpenFlow  traffic (\texttt{packet-in} messages) from the ingress switch to the controller.
Then, for each OpenFlow (OF) request, the controller performs a variable, application-dependent number of read and write operations, of different sizes, in the data store.
\item The number of read and write operations, along with its payload size (i.e., the \textit{workload}), was then recorded for each application.

\item Second, the collected workload traces were used to measure the performance of our distributed data store.
For the experiments we used four machines, three for the distributed
data store\footnote{To tolerate the crash from a single controller
  ($f=1$) three replicas are needed, as explained in Section
  \ref{architecture}.} and one for the controller (the data store
client).

\item The traces for each workload seen in this chapter is available online (\cite{support} appendix
  A). In there the reader can find: a script automating the data plane
  events in Mininet that trigger the OpenFlow messages as well as a recording of
  both the data plane events and data store messages characteristics
  (i.e., workloads).  


\item Each workload (and all its composing operations)  was run 50 thousand
times, measuring both latency and throughput. We calculated averages
and deviations in the 90, 95 and 99th percentile. Unless stated
otherwise the values shown in this chapter are in the 90th
percentile. The online support documentation (\cite{support}  appendix
B) of this document contains all (appendix  A - Micro results)


\end{itemize}

\subsubsection{We don't evaluate the data store}
\begin{itemize}
\item We don't use the real data store, we just replay equal size
  messages. In practice, we evaluate the middleware. 
\end{itemize}

\subsubsection{Explain what people will see in this chapter}
\begin{itemize}
\item GET key-take away from EWSDN paper. 
\item a functional description of the applications modified;
\item an iterative description of the optimization process we have
  followed along the curse of our work leading the the development of
  the data store functionalities covered previously
\item a micro benchmark study (WHAT is micro?) of the data store
  performance when dealing with real world applications expressed in
  terms of data plane events
\item Maybe give an example

\end{itemize}


\subsubsection{Development Environment characteristics}
\begin{itemize}
\item[Quinta hardware] Each machine had two quad-core 2.27 GHz Intel
  Xeon E5520 and 32 GB of RAM memory, and they were interconnected with gigabit Ethernet.
\item Versions of Mininet (mininet problem pointer) \footnote{Version
    2.0 (mininet-2.0.0-113012-amd64-ovf) available at
    \url{http://mininet.org}}. We had an issue with this version that
  caused hosts to offer gratuitous traffic that interfered with our
  experiences. We solved by disabling \gls{ipv6} in the virtual
  machine used to run Mininet\footnote{This is a known problem
      http://goo.gl/DQ7FQF
      (contains the solution followed)}. 
\item Floodlight is available online \footnote{\url{http://goo.gl/RbBXag} commit 9b361fbb3f84629b98d99adc108cddffc606521f}. 
\item Version of smart
  \footnote{\url{http://code.google.com/p/bft-smart} revision 335} 
\end{itemize}


\section{Learning Switch}
\label{sec:feasibility:ls}
\glsresetall
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[ht]

  \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/ls-events-broadcast}
                \caption{Broadcast packet.}
                \label{fig:ls:interaction:broadcast}
        \end{subfigure}%
        ~
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/ls-events-unicast}
                \caption{Unicast packet.}
                \label{fig:ls:interaction:unicast}
        \end{subfigure}
        \caption[Learning Switch workloads]{Broadcast packets trigger a write for the source address of the respective packet. Unicast packets have to additionally read the source address port location.}
        \label{fig:ls:interaction}
\end{figure}

The Learning Switch application emulates the hardware layer 2 switch
forwarding process. 
For each switch a different \emph{\texttt{MAC}-to-switch-port}
table is maintained in the data store. 
Each table is populated using the source address information (i.e.,
\texttt{MAC} and port)  presented in every OpenFlow \texttt{packet-in}
request for the purpose of maintaining the location of devices. 
After learning this location, the controller can install
rules in the switches to forward packets from a source to a
destination. 
Until then, the controller must instruct the switch to
\emph{flood} the packet to every port, with the exception of
the ingress port (where the packet came in from). Despite being distributed, each switch-table is
only accessed by the controller managing the switch in
question. 
Even so, we justify the study  of this application for two
reasons: (i) it benefits from the fault-tolerance property of
our distribution and (ii) it is commonly used as the
single-controller benchmark application in the literature \cite{Tootoonchian:2012uia}. 

\todo{to be common you need more than 1 example}
\note{Nao esta  claro que a tabela nesta app e single
  reader, single writer. NInguem entendeu...}

Figure \ref{fig:ls:interaction}  shows the detailed interaction between the
switch, controller (Learning Switch) and data store for two possible
cases. First (figure \ref{fig:ls:interaction:broadcast}), the case for broadcast packets that require
one write operation to store the switch-port  of the
source address. Second (figure \ref{fig:ls:interaction:unicast}),   the case for unicast
packets, that not only stores source information, but also read the
switch egress port for the destination address.  


\begin{description}
\item Original application maintains an hash table associating a
  switch with another hash-table  of macvlanpain to ports. This fits
  natural in our Key-Value model.
\item The original application has concurrency control. This fits
  natural in our application.
\item  The smart reader, will notice that if it has concurrency
  control, it should mean that tables are accessed by different
  clients . But in fact is that tables may be accessed by different
  services, as for example through the existent REST API. 
\item There isn't any problem since KeyValueTable is  thread safe (see
  \ref{section.datastore.thread.safety}) 

\end{description}

\subsubsection{Least Recently Used Cache}
\begin{itemize}
\item Critical that the switch table is limited due to resource
  usage. Remember that each table can potentially keep an entry for
  each host present in the network! 
\item Also MAC addresses must be recycled as devices enter and leave
  the network. 
\item By default limited, 1K hosts per table. 

\item What is it? The LRU discards the least recently used items
  first. For this, whenever an entry is accessed, it moves to the top
  of the list. Whenever and entry is added to the table, but the
  capacity is in the limit, the last entry in the access list is
  removed, to give room to the new one.

\item Why does the Learning Switch uses it ?  This way active devices
  are given priority in the table, as opposed to inactive devices. 
\item  We replicate this kind of table in the data store. Which was fairly simple. 
\end{itemize}

\subsubsection{Recycling MAC's}
\begin{itemize}
\item The application is configured with a idle timeout of 5 and a hard timeout of 0 seconds. As such the switch deletes the entry after 5 seconds of inactivity. This will result in a delete from the switch table that will trigger an OpenFlow \texttt{FLOW\_REMOVED } message from the switch to the controller. The Learning switch applications will process this OF message and delete the corresponding entry in the data store. Then, (immediately after) it will instruct the switch the remove the reverse entry from its table. The switch upon processing this message will trigger another \texttt{FLOW\_REMOVED} message to the controller.  This recursive process is not infinitive. The switch will only trigger \texttt{FLOW\_REMOVED} messages when it deletes an entry from the table. If the controller instructs it to remove something that isn't there, we will not trigger any message (sec. 6.4 of \cite{openflow-spec}). 
\end{itemize}

\subsection{Broadcast Packet}
Figure                \label{fig:ls:interaction:broadcast}
This workload corresponds to the operations performed in the data
store when processing broadcast packets in a OpenFlow
\texttt{packet-in} request.  Table \ref{table:lsw0:broadcast} shows that for the
purpose of associating the source address of the packet to the ingress
switch-port where it was received, the Learning Switch application performs one
write operation with a request size of 113 bytes and reply size of 1
byte. 

\begin{table}[ht]
\centering 
\begin{tabular}{l c c c c}
 Operation & Type & Request & Reply \\ \toprule 
 Associate source address to ingress port & W & 113 & 1 \\ \bottomrule
\end{tabular}
\caption[Workload lsw-0-broadcast( Broadcast Packet) operations]{Workload lsw-0-broadcast( Broadcast Packet) operations and sizes (in bytes).}
\label{table:lsw0:broadcast}
\end{table}

\subsection{Unicast Packet}
Figure                \ref{fig:ls:interaction:unicast}
Workload \textbf{lsw1-1} is the result of processing an OpenFlow request
triggered by an unicast packet. Thus,  when compared to the previous
workload (\textbf{lsw1-0} covering broadcast packets), an additional
operation is required to query the switch-port location of the
destination address. Table \ref{table:lsw0:unicast} provides a summary all the data
store operations in this workload. 

\begin{table}[ht]
\centering 
\begin{tabular}{l c c c c}
 Operation & Type & Request & Reply  \\ \toprule 
 Associate source address to ingress port & W & 113 & 1\\\midrule
Read egress port for destination address & R & 36 & 77 \\\bottomrule
\end{tabular}
\caption[Workload lsw-0-unicast( Unicast Packet) operations]{Workload lsw-0-unicast( Unicast Packet) operations and sizes (in bytes).}
\label{table:lsw0:unicast}
\end{table}

\subsection{Optimizations}


\subsubsection{Very simple Workloads}
\begin{itemize} 
\item Not much to do. 
\item Improve on size, given that it is a huge waste. $113 +1 + 36+
  77 = 227$  for the lsw-0-unicast workload. We can actually improve
 on that with : $29 +1 + 27 + 6 = 63$. A size of reduction of 
 72\% . We do this mainly by replacing
 the Java Serialization process by a manual serialization. 
\item  Present the table. Broadcast workload corresponds to the first
  line of the unicast workload (as before).  table \ref{table:lsw1:unicast}
\end{itemize}

\begin{table}[ht]
\centering 
\begin{tabular}{l c c c c}
 Operation & Type & Request & Reply \\ \toprule 
Associate source address to ingress port & W & 29 & 1\\\midrule
Read egress port for destination address & R & 27 & 6 \\\bottomrule
\end{tabular}
\caption[Workload lsw-1-unicast( Unicast Packet) operations]{Workload lsw-1-unicast( Unicast Packet) operations and sizes (in bytes).}
\label{table:lsw1:unicast}
\end{table}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{../data/reportGenerator/lsw-0-broadcastlsw-0-unicastlsw-1-broadcastlsw-1-unicasttxLatCmp.pdf}
\caption[Learning Switch workloads performance comparison]{Learning Switch workloads performance comparison (90th percentile). }
\end{figure}

\begin{itemize}
\item No noticeable  different between implementations. But noticiable
  difference between the two kind of workloads: unicast and
  broadcast. 
\item 20K with 3 ms latency for broadcast packets. 
\item 12K under 3 ms latency for unicast packets. 

\item We can join the operations together, and get the same kind of
  performance we get from the broadcast case. Notice that when joining the
  messages sizes we won't get a superior message workload (SUM UP
  VALUES TO BE CLEAR) for the previous implementation. But it is not
  worth it, since we can use cache.
\end{itemize}

\subsection{Cache}

\label{sec.learning.switch.lru.cache} Discuss cache implications of
least recently used. 

\subsubsection{Single Reader, Single Writer application}
\begin{itemize}
\item We do not loose consistency when introducing cache.
\item The reader can think of an exception where we find stale data:
  when a host moves from a switch to another, the tables from the
  first switch will have 
  incorrect data and devices will be unreachable from that switch from
  some time. But this also happens with the centralized version
  also. This is why rules installed in the switches must have a idle
  and hard timeout set. When one of the timeouts expire the switch triggers
  an \texttt{FLOW\_REMOVED} message to the controller, that in turns
  deletes the respective information in the data store. 

\todo{Confirma que isso acontece no mn} 

\end{itemize}


\subsubsection{Least Recently Used} 

\subsubsection{Cache Improvement not in the workload, but in the long
  run}
\begin{itemize}
\item We don't improve on the workload.  
\item We don't actually improve on the micro-benchmarks tested measures
shown throughout this chapters. We do not improve simply because with
cache we do not avoid or improve (by size reduction) any of the data store interactions
present in table \ref{table:work:lsw1-1} (that shows the latest
learning switch workload).  With cache we will only improve on the
long run, since we can now avoid the two type of requests present in
that table.

\begin{itemize}
\item First we can avoid re-writing the source address to source
port association when we already now it. 

\item In the original Learning Switch this re-write is not costly ($\Omega(1)$ ) and
  has the functional impact of refreshing the entry timestamp such that
  the least recently used table can keep up consistently with the last
  active host and delete the not inactive ones (that may have move or disconnect). 

\item  With our implementation this is much more expensive. 

\item Now, the active host
actually gets forgotten somewhere in time as newly (unknown) entries
are added to the data store. 

\item We expect this to be ok since the host,
being active, will benefit in latency a lot before actually being
erased from the data store due to the newly added hosts. 

\item When avoiding this write
in the cache implementation we must actually be sure that we only
avoid to write to the data store when the association is known in
cache and it is actually correct (the ingress port is the same from
the packet being processed). 
\end{itemize}

\begin{itemize}
\item The second avoidance is the read operation that queries for the egress
port of the current processed packet. We do not actually need to read
from the data store if the entry is present in the cache. First the
data is not modified by any other controller since we are the only
ones which manipulate our switch tables. 


\end{itemize}
\item With cache we no longer read from the database. We do not need since
put updates the cache. So if it isn't on the cache it is not in the
data store.

\item No need for timed interface. Just avoid. When rules expire in
  the switches, they are removed from the data store (and the cache
  consequently). 
\end{itemize}


\section{Load Balancer}
\label{sec:feasibility:lb}
\glsresetall
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Load Balancer main idea} 
\begin{itemize}
\item The Load Balancer application employs a round-robin algorithm to distribute the
requests addressed to a \gls{vip} . 

\item In order to
understand its behaviour we begin by the data model currently used. Figure
\ref{fig:lb-model} shows the three different entities used in the Load
Balancer. The \gls{vip} entity represents a virtual endpoint with a specified \gls{ip}, port and
protocol address. Each \gls{vip} can be associated with one or more pools of 
servers. Given that the distribution algorithm is round-robin, each pool
has a current assigned server (\texttt{current-member} attribute in the figure). Finally, the third entity --- Member
--- represents a real server. 
\item Each of those entities, corresponds
to a different  table  in the data store, indexed by the entity
key attributes represented in the figure (in bold). Moreover, a fourth table is
required to associate \gls{ip} addresses to VIP resources. 



\end{itemize}

\begin{figure}[ht]
\TopFloatBoxes
\begin{floatrow}
\ffigbox{
\includegraphics[scale=0.6]{./pic/feasibility/lb-model.pdf}
}{\caption{\small Simplified Load Balancer entities data model. The data
store contains a table for each entity, indexed by their keys (represent as bold attributes). }
\label{fig:lb-model}}


\capbtabbox{
\small
\begin{tabular}{cccc}
  Name & Key & Value & \\ \toprule
vips  & vip-id  & vip   \\\midrule
pools & pool-id &  pool \\\midrule
members & member-id  & member    \\\midrule
vip-ip-to-id &  ip & vip-id   \\\midrule
member-ip-to-id & ip  & member-id \\ \bottomrule 

\end{tabular}
}{\caption[Load Balancer key-value tables]{Load Balancer key-value tables.}
\label{tablle:lb:indexes}}
\end{floatrow}
\end{figure}

\begin{itemize}
\item In light of
this data model, the load balancer logic requires the following
operations from the data store: (i) check if the source address is
associated with a VIP resource; (ii) if so, read the VIP, Pool and
Member information required to install flows in the switch and (iii)
update the pool \texttt{current-member} attribute. This description corresponds to the case where OpenFlow\texttt{packet-in} requests are indeed addressed at a VIP
resource. The respective workload which, is the heavier in
the Load Balancer application, is in figure 
\ref{fig:lb:interaction:ip2Vip} section ahead. Alternatively, figure 
\ref{fig:lb:interaction:arp2VIp}  considers the special case of ARP requests questioning the hardware
address of a VIP \texttt{IP}.
\end{itemize}


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/lb-events-broadcast}
                \caption{ARP packet address at a VIP.}
                \label{fig:lb:interaction:arp2Vip}
        \end{subfigure}%
        ~
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/lb-events-unicast}
                \caption{IP packets addressed at a VIP. }
                \label{fig:lb:interaction:ip2Vip}
        \end{subfigure}
        \caption[Load Balancer workload events]{A \texttt{\gls{arp}} request message addressed at a VIP \gls{ip} that results in a direct \gls{arp} reply. On the left a normal \gls{ip} packet addressed at VIP should be resolved (who is responsible) and replied by installing the appropriate rules}  
        \label{fig:lb:interaction}
\end{figure}

\subsection{Packets to a VIP}
When the Load Balancer  receives a data packet addressed
at a VIP, it triggers the operations seen in table
\ref{table:lbw-0-ip-to-vip}. 
The first operation fetches a VIP resource associated with the
destination \texttt{IP} address of the packet.
If it succeeds (reply different from 0), then it proceeds to read 
the chosen pool for the returned  VIP\footnote{The current implementation of this
application always chooses the first existent pool.}.
Afterwards it updates (third operation) the fetched  pool, along with the newly modified
\texttt{current-member}.
The forth and final operation retrieves
the address information for the selected  Member. 

\note{ discutir a questão de update concorrente (segunda e  terceira operacao )}


\begin{table}[H]
\centering 
\begin{tabular}{l c c c c}
 Operation & Type & Request & Reply \\ \toprule 
 
Get VIP id for the destination IP & R & 104 & 8\\\midrule
Get VIP Info (pool information) & R & 29 & 509\\\midrule
Get the choosen pool & R & 30 & 369\\\midrule
Conditional replace pool after round-robin & W & 772 & 1\\\midrule
Read the chosen Member & R & 32 & 221 \\\bottomrule
\end{tabular}\caption[Workload lbw-0-ip-to-vip( IP packet to a VIP)
operations]{Workload lbw-0-ip-to-vip( IP packet to a VIP) operations
  and sizes (in bytes).}
\label{table:lbw-0-ip-to-vip}
\end{table}



\subsection{ARP Request}
This workload  results  from processing an ARP Request addressed at a
VIP address. The data store operations, summarized in Table
\ref{table:lbw-0-arp-request}, shows that two reads are
required. First, as previously seen,  it queries the data
store to check if the packet destination address is a VIP (1 read
needed). As it is, the controller then retrieves the \texttt{MAC} address for that
VIP server (so, another read is needed).

\begin{table}[ht]
\small
\centering 
\begin{tabular}{l c c c c}
Operation & Type & Request & Reply \\ \toprule 
Get VIP id for the destination IP  & R & 104 & 8\\\midrule
Get VIP info (proxy MAC address) & R & 29 & 509 \\\bottomrule
\end{tabular}\caption[Workload lbw-0-arp-request( Arp Request to a
VIP) operations]{Workload lbw-0-arp-request( Arp Request to a VIP)
 operations and sizes (in bytes).}
\label{table:lbw-0-arp-request}
\end{table}



\subsection{Optimizations}
\subsubsection{Normal Packets}

\begin{itemize}
\end{itemize}


\subsubsection{Optimization table}

\begin{table}[H]
\small
\begin{tabular}{llccccc}
 Operation & Type &  \multicolumn{5}{c}{ (Request, Reply) } \\  \midrule
&  & lbw-0 & lbw-1  & lbw-2 & lbw-3 & lbw-4 \\ \toprule 
%& &   \multicolumn{5}{c}{(Request, Reply)} \\midrule 
Get VIP id of destination IP  & R & (104,8) &\multirow{2}{*}{(104,509)} &  \multirow{2}{*}{(104,513)} &\multirow{2}{*}{\textbf{(62,324)}} & \multirow{2}{*}{-}    \\\cmidrule{1-2} 
Get VIP info (pool)   & R &  (29,509) & & & &   \\ \midrule 
Get the choosen pool  & R & (30,369)  &  - & (30,373) & -   & \multirow{3}{*}[-2mm]{\textbf{(11,4)}}  \\  \cmidrule{1-2} 
Replace pool after round-robin  & W & (772,1) & -
&\textbf{(403, 1)} &  - \\ \cmidrule{1-2}  
  Read the chosen Member &  R & (32,221) & - & (32,225) & \textbf{(44,4)} & \\\bottomrule  
\end{tabular}\caption[Load Balancer IP to VIP workload operations across
diferent implementations.]{Load Balancer  lbw-\textit{X}-ip-to-vip workload
  operations and respective sizes (in bytes) across diferent
  implementations. Bolded sizes represent significant differences
  across implementations. Sizes marked with \texttt{-} are equal to
  the previous. } 
\end{table}


\begin{figure}[ht]
% \CenterFloatBoxes
%\TopFloatBoxes  
% \BottomFloatBoxes
\begin{floatrow}
\ffigbox{%
  \includegraphics[scale=0.4]{../data/reportGenerator/lbw-0-ip-to-viplbw-1-ip-to-viplbw-2-ip-to-viplbw-3-ip-to-viplbw-4-ip-to-viptxLatCmp.pdf}
}{\caption{Cenas}%
}


\capbtabbox{%
\small
  \begin{tabular}{lll} 
    Prefix &  Data store & Section\\\toprule
    lbw-0 & Simple Key-Value  & \ref{sec:}  \\
    lbw-1 & Cross References  & \ref{sec:} \\
    lbw-2 & Versioned Values & \ref{sec:} \\
    lbw-3 & Column Store & \ref{sec:} \\
    lbw-4 & Micro Components & \ref{sec:} \\ \bottomrule
    & &  \\ 
    & &  \\ 
    & &  \\ 
    & &  \\ 
    & &  \\ 
  \end{tabular}
}{%
  \caption[Name guide to Load Balancer workloads]{Name guide to Load
    Balancer workloads.}\label{table:lb-versions}
}
\end{floatrow}
\end{figure}


\begin{itemize}

\item introduce table.  Ip to VIP ! Similar as before, but this time, we show a
  different implementation of the Load balancer application and the
  respective impact in the workload.  From left to right we should
  verify improvement. 

\item The improvements use different data store functionalities. For
  reference/completeness table \ref{table:lb-versions} associates the workload
  prefixes used (i.e., lbw-0, lbw-1, ... , lbw-4) to the data store
  functionality used. 

\item lbw-0 refers to the most simple key-value store implementation,
  which has already been presented in table
  \ref{table:lbw-0-ip-to-vip} that summarized the workload.


\item Message size is now grouped in tuples. If a implementation does
  not changes the messages size from the previous we mark that with
  \texttt{-} symbol.  Whenever there is a significant change in size
  we shot the messages in bold. Merged cells reflect message merging. 


\begin{itemize}
\item \textbf{Cross Reference} (lbw-1) 
\item merge messages. No need to get the an id in the first
  message and then the vip (obtained with the first id) 
\item  So both arp request and the packet address at a VIp workloads show
requests that first obtain the VIP id and only aftewards read the VIP
from the VIP table using the obtained id. So we can improve our
workload footprint by directly obtaining the VIP with only the first
request. 
\end{itemize}

\begin{itemize}
\item \textbf{Versioned Values} (lbw-0)
\item Cut size in half. 
\item The conditional replace (after round-robin) in the 4th line is
  requires sending two pools: the original one fetched and the
  modified one.  Then only if the original pool matches the one
  present in the data store, the new pool will be inserted. If not the
  operation fails. 
\item By using version numbers associated with each entry in the data
  store, we could potentially replace the values. 
\item Notice that read operations now have an increased 4 bytes for
  the version number. 
\end{itemize}

\begin{itemize}
\item \textbf{Columns}
\item We tried to optimize by using columns. But not much success
\item Obtain the pool actually requires read a lot of he fields of the
  original value for later processing. So the size reduction is not
  significant. 
\item Obtaining the member is actually a good increase. The reply
  size is now 56 times lower than before. 
\end{itemize}

\begin{itemize}
\item \textbf{Micro Components}
\item We can't avoid going to the data store for fetching and updating
  the pool, for the round robin algorithm
\item A form of optimistic concurrency control that will certainly
  fail a lot if different controllers manipulate the same pools. (so
  it would be beneficial, if by design, pools were partitioned across
  controllers)
\item So we can merge the three operations in a \texttt{round-robin}
  method that returns the required member information. 
\end{itemize}
\end{itemize}

\subsubsection{Analysis}
\begin{itemize}
\item We see the same pattern again. 
\item Size reduction in the same order of magnitude, do not have any
  practical impact.
\item Message reduction has a great impact. 
\item Minor improvement from 0 ( 4.5k/s,  4 ms) to  1 (6.1k , 6.7) ms,
  caused by message reduction. 
\item Message size reduction across the three workloads: 1,2 and 3
  does not have a deep impact. As can be see in the graphic it is not
  enough to differentiate the lines. 
\item  But message reduction, in the last workload (4) , with
  Micro-Components, pays off a lot. 12kFlows/s with 5 ms latency. An
  improvement of more than double from the original workload, with
  only a 25\% increase in latency. 
\end{itemize} 


In the ARP request case  we improve by using cross references tables
to join the two requests into one (lbw-1-arp-request). With the column
based implementation we improve slightly by reducing the size of the
requests as I see.

\subsection{Cache}

\subsubsection{What to cache. Effects of cache}

\begin{itemize}
\item Considering the ip-to-a-vip workload
\item Fetching the vips  can be cached. 

\item VIP information can be invalid. We try to reach a VIP that does not
  exist anymore for some reason, or may have changed IP address to
  start providing another service. This can happen already in the
  strongly consistent version. When we fetch a VIP from the data
  store, it can already be invalid, by the time we get it
  locally. With cache the probability is greater.  

\item Updating the timestamps can not be cached. 
\end{itemize}

\subsubsection{The reason columns are so big}
\begin{itemize}
\item We fetch \gls{vip} entities in two different workloads: arp
  requests, ip to VIP. 
\item fetch the union of the information required for the two
operations.
\item may be beneficial if the flows are dependent of one another
\item  When processing the first we can be sure that unless some
anomaly happens the hosts performing the arp request will consequently
trigger the second flow processing.
\item So we benefit from having the
information in cache to avoid having to perform another request just
because a field is missing. 
\end{itemize}

\subsubsection{Why cache can be so important}



\begin{itemize}
\item Minimum footprint of this application in the overall controller
  pipeline. 
\item Even when processing a normal packet, not related to a VIP address at
all, the Load Balancer still has to find out if this is the case. This
workload, which only requires one operation (see table (First line of tables))
\ref{table:lbw-0-ip-to-vip,table:lbw-0-arp-request} but with  a 0 byte
reply) sets the minimum amount of work imposed by
the Load Balancer to the controller pipeline. 
\item Empty values. 

%Ideally we should also avoid the normal case of IP packets not
%addressed at a VIP. For this our cache  must understand what a empty
%value means FIXME. (use containsInCache . update to insert empty in
%cache. Then see if containsInCache AND get == null you can be certain
%the value is not a VIP), completely avoiding the going to the data store.
\end{itemize}



\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{./../data/reportGenerator//lbw-3-ip-to-notviptxLat.pdf}
\caption[Minimum impact of Load Balancer in the pipeline.]{Workload
  lbw-3-ip-to-notvip shows the minimal impact the Load Balancer
  applications has on the pipeline in our best implementation.}
\end{figure}


\subsubsection{Cache}

\section{Device Manager}
\label{sec:feasibility:dm}
\glsresetall
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The Device Manager application tracks and stores host devices
information such as the switch-ports to where devices are
attached to\footnote{The original application is able to track devices as
  they move around a network, however our current implementation does
  not take this feature into consideration.}. This information ---
that is retrieved from the OpenFlow packets that the controller receives --- is crucial to
Floodlight’s Forwarding application. That is to say, that for  each new flow, the Device
Manager has the job of finding a switch-port for both the destination
and source address. Given this information, it is able to pass it to
the Forwarding application, that can later decide on the actions to
take (e.g., best route). Notice that this arrangement, excludes the
Learning Switch as the  forwarding application in action. 

Regarding the data store usage, Device Manager requires three
data store tables listed in table \ref{table:dm:indexes}.  The first
table, \texttt{devices} keeps track of known devices created by the
application. A second table named \texttt{macs}  indexes those same devices by their
\gls{mac} and \gls{vlan}  pair.  Finally, a third table named
\texttt{ips} maintains an index from an \gls{ip} address to one or
more devices.


\begin{table}
\small
\begin{tabular}{cccc}
Name & Key & Value & \\ \toprule
devices & device-id &  device \\\midrule
macs & (MAC,VLAN)  & device-id   \\\midrule
ips  & IP & device-id list \\\midrule
\end{tabular}
\caption[Device Manager key-value tables]{Device Manager key-value tables.}
\label{table:dm:indexes}
\end{table}

We will analyze and improve on  two distinct workloads for this application differing in
wether the application already knows the source device information (
figure \ref{fig:dm:interaction:known})
or not ( \ref{fig:dm:interaction:unknown}). 

In the former case, the
application mainly reads information from the data store in order to
obtain location information. As for the latter case, the
application must create the device information and updates all the
existent tables. Therefore, this workload generates more traffic between
the controller and data store. 


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/dm-unknown}
                \caption{Packet from an unknown device.}
                \label{fig:dm:interaction:unknown}
        \end{subfigure}%
        ~
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{pic/feasibility/ls-events-unicast}
                \caption{Packet from a known device.}
                \label{fig:dm:interaction:known}
        \end{subfigure}
        \caption[Device Manager workload events]{Workloads for this application heavily depend on the state of the data store. Unknown devices trigger several operations to the creation of these, while known devices only require an update of their "last seen" timestamp. No matter the case, the source and destination devices are retrieved if they exist.}
        \label{fig:dm:interaction}
\end{figure}

\subsection{Known Devices}

\begin{table}[ht]
\small
\centering 
\begin{tabular}{l c c c c}
Operation & Type & Request & Reply \\ \toprule 
Read the source device key & R & 408 & 8\\
Read the source device & R & 26 & 1444\\
Update "last seen" timestamp & W & 2942 & 0\\
Read the destination device key & R & 408 & 8\\
Read the destination device & R & 26 & 1369 \\
\end{tabular}
\caption[Workload dm-0-known (Known Devices) operations]{Workload
  dm-0-known (Known Devices) operations and sizes (in bytes).}
\label{table:ops:dm-0-known}
\end{table}

When devices are known to the application, a \texttt{packet-in} request
triggers the operations seen in table \ref{table:ops:dm-0-known}. The
first two operations read source and destination device
information in order to make their switch-ports available to the
Forwarding process. Additionally, the second operation (a write), 
updates the ``last seen'' timestamp of the source device.

\subsection{Unknown Source}
\small
\begin{table}[ht]
\centering 
\begin{tabular}{l c c c c}
Operation & Type & Request & Reply \\ \toprule 
1) Read the source device key & R & 408 & 0\\
2) Get and increment the device id counter & W & 21 & 4\\
3) Put new device in device table & W & 1395 & 1\\
4) Put new device in \texttt{(MAC,VLAN)} table & W & 416 & 0\\
5) Get devices with source IP & R & 386 & 0\\
6 ) Update devices with source IP & W & 517 & 0\\
7) Read the destination device key & R & 408 & 8\\
8) Read the destination device & R & 26 & 1378 \\\bottomrule
\end{tabular}
\caption[Workload dm-0-unknown( ARP from Unknown Source)
operations]{Workload dm-0-unknown( ARP from Unknown Source) operations
  and sizes (in bytes).}
\label{table:ops:dm-0-unknown}
\end{table}


This workload is triggered in the specific case in which  the source device
is unknown and the \gls{OF} message carries an \gls{arp} reply 
packet. Seing that both these  conditions are true, the application
proceeds  with 8 data store operations, described in table
\ref{table:ops:dm-0-unknown}. Their intention is to create device
information and update the three tables described  in the beginning
of this section.  

The first operation reads the  source device key. Being
that it is not known, this operation fails (notice in the table, that
the reply has a size  of zero bytes). As a result the application
proceeds with the creation of a device. For this, the
following write (second operation) atomically retrieves
and increments a device unique \texttt{id} counter. Afterwards, the third and fourth  operation
update, with the newly created device, the device and MAC/VLAN
tables respectively. Likewise, the fifth and sixth operations update
the \gls{IP} index table. Given that this index links an \gls{IP} to
several devices we are forced to first collect the set of devices in
order to update it. This \emph{read-modify} operation can
fail in case of concurrent updates. Under that case, both operations
would be repeated until they succeed. At this point, the Device Manager
is done with the creation of the device and can, finally, move to the
last two operations to fetch the destination device information. 

\subsection{Optimizations}
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{../data/reportGenerator/dm-0-unknowndm-1-unknowndm-2-unknowndm-3-unknowndm-4-unknowntxLatCmp.pdf}
                \caption{}
                \label{fig:}
        \end{subfigure}%
        ~
        \begin{subfigure}[b]{0.5\textwidth}
                \centering
                \includegraphics[width=\textwidth]{../data/reportGenerator/dm-0-knowndm-1-knowndm-2-knowndm-3-knowndm-4-knowntxLatCmp.pdf}
                \caption{}
                \label{}
        \end{subfigure}
        \caption[Device Manager performance analysis]{}
        \label{fig:dm:performance}
\end{figure}

\begin{table}
\small
\begin{tabular}{lll} 
    Prefix &  Data store & Section\\\toprule
    dm-0 & Simple Key-Value  & \ref{sec:heimdall:datastore:kv}  \\
    dm-1 & Cross References  & \ref{sec:heimdall:datastore:cr} \\
    dm-2 & Versioned Values & \ref{sec:heimdall:datastore:vr} \\
    dm-3 & Column Store & \ref{sec:heimdall:datastore:cr} \\
    dm-4 & Micro Components & \ref{sec:heimdall:datastore:mc} \\ 
  \end{tabular}
  \caption[Name guide to Device Manager workloads]{Name guide to
    Device Manager workloads.}
  \label{table:names:dm}
\end{table}

\begin{table}[ht]
\small
\centering
\begin{threeparttable}
\begin{tabular}{ll ccccc}
 Operation & Type &  \multicolumn{5}{c}{ (Request, Reply) } \\  \midrule
&  & lbw-0 & lbw-1  & lbw-2 & lbw-3 & lbw-4 \\ \toprule 
Get source key & R &(408, 8) & \multirow{2}{*}{(408,1274)} &
\multirow{2}{*}{(408,1278)} & \multirow{2}{*}{(486,1261)} &
\multirow{2}{*}{(28,1414)} \tnote{a} \\ \cmidrule{1-2}
Get source device & R & (26,1444) & & & & \\ \midrule
Update timestamp & W & (2942,0) & (2602,0) & (1316,1) & (667,1) & 
(36,0) \\ \cmidrule{1-2}
Get destination key & R & (408,8) & \multirow{2}{*}[-1mm]{(408,1199)} &
\multirow{2}{*}[-1mm]{(408,1203)} & \multirow{2}{*}[-1mm]{(416,474)} &
\multirow{2}{*}[-1mm]{N/A} \\ \cmidrule{1-2}
Get destination device & R & (26,1369) &  &
 & & \\\bottomrule
\end{tabular}
\caption[Workload dm-0-known( Known Devices) operations]{Workload
  dm-0-known( Known Devices) operations and sizes (in bytes).}
\begin{tablenotes}
\item [a)] This operation also fetches the destination device.
\end{tablenotes}
\end{threeparttable}
\end{table}

%TODO - do not use put new device in MAC,VLAN table. This is
%confusing. 

\begin{table}[ht]
\small
\centering 
\begin{threeparttable}
\begin{tabular}{ll ccccc}
 Operation & Type &  \multicolumn{5}{c}{ (Request, Reply) } \\  \midrule
&  & lbw-0 & lbw-1  & lbw-2 & lbw-3 & lbw-4 \\ \toprule 
Read source key & R & (408,0) & - & - & (486,0) & (28,201)\tnote{a}\\
Increment counter & W & (21,4) & -  & - & - & \multirow{5}{*}{(476,8)} \\
Update device table & W & (1395,1) & (1225,1)\tnote{b}  & - &
(1183,1) & \\
Update MAC  table & W & (416,0) & - & - & -
& \\
Get from IP index & R & (386,0) & - & - & - & \\
Update IP index  & W & (517,0) & - & - & - & \\
Get destination key & R & (408,8) &
\multirow{2}{*}{(408,1208)}\tnote{b} & \multirow{2}{*}{(408,1212)} &
\multirow{2}{*}{(416,474)} & \multirow{2}{*}{N/A}  \\ 
Get destination device & R & (26,1378)  &  & & \\\bottomrule
\end{tabular}
\caption[Workload dm-0-unknown( ARP from Unknown Source)
operations]{Workload dm-0-unknown( ARP from Unknown Source) operations
  and sizes (in bytes).}
\begin{tablenotes}
\item [a)] This operation also fetches the destination device.
\item [b)] Differences in sizes caused by a SERIALIZATION improvement 
\end{tablenotes}
\end{threeparttable}
\end{table}


\subsubsection{Cross References tables}
\begin{itemize}
\item So in practice we have to get the device key from the mac/vlan
  table and only then we can actually get the device information we
  want. This is redudant, and we can actually perform the all
  operation instantaneously  by using cross references tables. 

\item 
\end{itemize}



\subsubsection{Timestamps}
\subsection{Cache}

\subsubsection{What to cache}
\begin{itemize}
\item Source device 

\item With cache we fetch known devices in an optimistic concurrency
manner.  If there is no such device in cache, we then try to obtain it
from the data store, as it might be created from other
controller. (Really? - yes same device with different routes that go
through different openflow controllers)

\item What we try to do is to fetch device from the cache. At some point in
time in a  normal network, we hope that all device information is
known. After that point devices in cache should pass the timestamp
update at first (if they are not updated by concurrent
controllers). If the devices are connected to different openflow
islands simultaneously than this is a bad idea since we will actually
have to perform one more request that the normal workload
pattern. (try to updated - fails, retrieve new , update) . Off course
this could be mitigated by having the update attempt to return the
currently present value timestamp..
\end{itemize}




\subsubsection{Columns}


\subsubsection{Micro Components}
Just a proof of concept. Establish special methods in the data store. 
Three : 
createDevice <-
updateDeviceTimestamp <- 
getTwoDevices <- could be done with transactions.  Gets the source
device entirely. Also gets the attachments points of the destination
device since these are required to forwarding. 

\subsubsection{Everything}
\begin{itemize}
\item the question that may arise: why not simply put everything inside the
  data store then? Well, in the case of the device manager, there are
  actually a few subitilidades hidden in our explanation. First there
  is a dependency of others services. topology manager. 
\end{itemize}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../PEI"
%%% End: 

